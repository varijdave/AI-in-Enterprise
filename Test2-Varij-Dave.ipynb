{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a774f2",
   "metadata": {},
   "source": [
    "# Test-2 by Varij Dave (100855095)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2d5e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec5b9bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train.csv dataset\n",
    "url = \"https://raw.githubusercontent.com/varijdave/AI-Algorithm/main/train.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f7e62",
   "metadata": {},
   "source": [
    "1. Drop the following attributes: Name, Ticket, PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca7ac818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified attributes\n",
    "df.drop(['Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac00f55",
   "metadata": {},
   "source": [
    "2. Check for missing values and:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1344ae",
   "metadata": {},
   "source": [
    "a. drop the whole column if it is missing more than 70% of its values,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4998a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with more than 70% missing values\n",
    "df.dropna(thresh=len(df) * 0.7, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4366b7e0",
   "metadata": {},
   "source": [
    "b. fill in the missing values with the mean of the attribute if it is a numerical attribute,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fef69c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in numerical columns with mean\n",
    "num_cols = df.select_dtypes(include='number').columns\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[num_cols] = imputer.fit_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012de7e",
   "metadata": {},
   "source": [
    "c. fill in the missing values with the mode of the attribute if it is categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e97a1b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in categorical columns with mode\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[cat_cols] = mode_imputer.fit_transform(df[cat_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e749c5",
   "metadata": {},
   "source": [
    "3. One hot encode Sex and Embarked attributes using get_dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a22a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode Sex and Embarked attributes\n",
    "df = pd.get_dummies(df, columns=['Sex', 'Embarked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c17134",
   "metadata": {},
   "source": [
    "4. Split the dataset into 60% for training, 20% for validation, and 20% for testing. Print the .shape for the created X_train, y_train, X_validation, y_validation, X_test, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "649db14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb9833b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51214ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (534, 10)\n",
      "y_train shape:  (534,)\n",
      "X_validation shape:  (178, 10)\n",
      "y_validation shape:  (178,)\n",
      "X_test shape:  (179, 10)\n",
      "y_test shape:  (179,)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes of the created datasets\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_validation shape: \", X_validation.shape)\n",
    "print(\"y_validation shape: \", y_validation.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e06c061",
   "metadata": {},
   "source": [
    "5. Train the following classifiers to predict if a passenger will survive:\n",
    "a. Logistic Regression\n",
    "b. Decision Tree\n",
    "c. Gaussian Na√Øve Bayes\n",
    "d. Support Vector Machine\n",
    "e. Random Forrest\n",
    "f. Gradient Boosting\n",
    "g. Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78650d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AI Algorithm\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Ada Boost': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8619fd03",
   "metadata": {},
   "source": [
    "6. Report on the .score(X_validation, y_validation) of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61a8606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate models - accuracy score\n",
    "accuracy_scores = {}\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    accuracy_scores[classifier_name] = classifier.score(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a855d5",
   "metadata": {},
   "source": [
    "7. Report on the f1_score(y_validation, y_predicted validation) of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0c3d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models - f1 score\n",
    "f1_scores = {}\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    y_pred = classifier.predict(X_validation)\n",
    "    f1_scores[classifier_name] = f1_score(y_validation, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d712f",
   "metadata": {},
   "source": [
    "8. Among the 7 models you trained, which one performed best? Limit your answer to 3 lines in a markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dce7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify best performing model\n",
    "best_model = max(accuracy_scores, key=accuracy_scores.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53e550",
   "metadata": {},
   "source": [
    "9. Test the best performing model and report on its .score(X_test, y_test) and f1_score(y_test, y_predicted_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f575d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores on validation set:  {'Logistic Regression': 0.7640449438202247, 'Decision Tree': 0.702247191011236, 'Gaussian Naive Bayes': 0.7471910112359551, 'Support Vector Machine': 0.6853932584269663, 'Random Forest': 0.7752808988764045, 'Gradient Boosting': 0.8033707865168539, 'Ada Boost': 0.8033707865168539}\n",
      "F1 scores on validation set:  {'Logistic Regression': 0.6666666666666666, 'Decision Tree': 0.5954198473282443, 'Gaussian Naive Bayes': 0.6666666666666666, 'Support Vector Machine': 0.36363636363636365, 'Random Forest': 0.6774193548387097, 'Gradient Boosting': 0.7008547008547009, 'Ada Boost': 0.7199999999999999}\n",
      "Best performing model:  Gradient Boosting\n",
      "Accuracy score on test set:  0.8100558659217877\n",
      "F1 score on test set:  0.7499999999999999\n"
     ]
    }
   ],
   "source": [
    "#Test the best performing model\n",
    "best_model_classifier = classifiers[best_model]\n",
    "best_model_classifier.fit(X_train, y_train)\n",
    "y_pred_test = best_model_classifier.predict(X_test)\n",
    "test_accuracy = best_model_classifier.score(X_test, y_test)\n",
    "test_f1_score = f1_score(y_test, y_pred_test)\n",
    "# Print results\n",
    "print(\"Accuracy scores on validation set: \", accuracy_scores)\n",
    "print(\"F1 scores on validation set: \", f1_scores)\n",
    "print(\"Best performing model: \", best_model)\n",
    "print(\"Accuracy score on test set: \", test_accuracy)\n",
    "print(\"F1 score on test set: \", test_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09957eb",
   "metadata": {},
   "source": [
    "10. Load the Titanic test.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f167faef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load test.csv\n",
    "url_test = 'https://raw.githubusercontent.com/varijdave/AI-Algorithm/main/test.csv'\n",
    "df_test = pd.read_csv(url_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d2a9b6",
   "metadata": {},
   "source": [
    "11. Preprocess the test.csv data the same way you preprocessed the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "586d34db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df_test = df_test.drop(['Name', 'Ticket', 'PassengerId', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a1f9b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with mean and mode\n",
    "df_test['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "df_test['Fare'].fillna(df['Fare'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e41a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical columns\n",
    "df_test_encoded = pd.get_dummies(df_test, columns=['Sex', 'Embarked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a32600",
   "metadata": {},
   "source": [
    "12. Use the same 7 models you used earlier to predict the number of survived passengers in the test.csv dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f796f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use trained models to predict survival in test.csv\n",
    "predictions = {}\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    predictions[classifier_name] = sum(classifier.predict(df_test_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7db8d4",
   "metadata": {},
   "source": [
    "13. Comparing the performance of all the models you have trained, how many passengers from the test set (test.cvs) do you think actually survived? Limit your answer to 3 lines in a markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fa27239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take majority vote from all models' predictions\n",
    "total_passengers = df_test.shape[0]\n",
    "survived_passengers = max(predictions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "917a7a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted number of passengers survived in test.csv:  179.0  out of  418\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"Predicted number of passengers survived in test.csv: \", survived_passengers, \" out of \", total_passengers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebad964",
   "metadata": {},
   "source": [
    "# Do I think they survived?\n",
    "The final count of survivors among passengers in the test.csv dataset cannot be determined for certain, as it is contingent upon the combined predictions of various trained models. This number is derived from the collective vote of all the models, and unfortunately, there is no \"Survived\" column in the test.csv dataset to confirm the actual survival of passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f64b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
